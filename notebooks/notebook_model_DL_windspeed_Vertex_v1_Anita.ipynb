{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC_-5-Y5sTKx"
      },
      "source": [
        "# 0.1 Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_tuner in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from keras_tuner) (3.7.0)\n",
            "Requirement already satisfied: packaging in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from keras_tuner) (24.2)\n",
            "Requirement already satisfied: requests in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from keras_tuner) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from keras_tuner) (1.0.5)\n",
            "Requirement already satisfied: absl-py in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from keras->keras_tuner) (2.1.0)\n",
            "Requirement already satisfied: numpy in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from keras->keras_tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from keras->keras_tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from keras->keras_tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from keras->keras_tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from keras->keras_tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from requests->keras_tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from requests->keras_tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from requests->keras_tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from optree->keras->keras_tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from rich->keras->keras_tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from rich->keras->keras_tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/anita/.pyenv/versions/3.10.6/envs/powder_alert2.0/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Ux0XQqlVsTKy",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from typing import Dict, List, Tuple, Sequence\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer, StandardScaler, LabelEncoder\n",
        "from sklearn.pipeline import make_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhpKRsA0sTKy"
      },
      "source": [
        "# 1. Data Import & Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4kOoKN40sTKz",
        "outputId": "e374baf1-9180-45db-f69b-1d942c6ce1d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/anita/code/MadMax1995bb/powder_alert2.0/notebooks'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ycpHyXxRsTKz",
        "outputId": "2d5e71bf-7607-4774-a939-60b52d77d567"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/anita/code/MadMax1995bb/powder_alert2.0'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "relative_path = os.path.dirname(current_dir)\n",
        "relative_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Xr0wp0IEsTKz"
      },
      "outputs": [],
      "source": [
        "file_name = \"raw_data/raw_fitting.csv\"\n",
        "\n",
        "file_path = os.path.join(relative_path, file_name)\n",
        "\n",
        "df = pd.read_csv(file_path, parse_dates=['date'], usecols=lambda col: col != '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-eoMyEpBsTK0"
      },
      "outputs": [],
      "source": [
        "# Drop the first weird column if it exists\n",
        "if 'Unnamed: 0' in df.columns:\n",
        "    df = df.drop(columns=['Unnamed: 0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9SUVMJxsTK0",
        "outputId": "b3cc7a73-b5ce-4539-d184-23f3150f98cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(131496, 23)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCOD5voBsTK0",
        "outputId": "93c2b9ea-aa26-4805-d5a2-3e2aec743ef8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['date', 'temperature_2m', 'relative_humidity_2m', 'dew_point_2m',\n",
              "       'precipitation', 'rain', 'snowfall', 'snow_depth', 'weather_code',\n",
              "       'pressure_msl', 'surface_pressure', 'cloud_cover', 'cloud_cover_low',\n",
              "       'cloud_cover_mid', 'cloud_cover_high', 'et0_fao_evapotranspiration',\n",
              "       'vapour_pressure_deficit', 'wind_speed_10m', 'wind_speed_100m',\n",
              "       'wind_direction_10m', 'wind_direction_100m', 'wind_gusts_10m',\n",
              "       'sunshine_duration'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "id": "yhoNYUOwsTK0",
        "outputId": "ab059111-30f0-44bc-db30-d0717a8f957f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "date                          datetime64[ns]\n",
              "temperature_2m                       float64\n",
              "relative_humidity_2m                 float64\n",
              "dew_point_2m                         float64\n",
              "precipitation                        float64\n",
              "rain                                 float64\n",
              "snowfall                             float64\n",
              "snow_depth                           float64\n",
              "weather_code                         float64\n",
              "pressure_msl                         float64\n",
              "surface_pressure                     float64\n",
              "cloud_cover                          float64\n",
              "cloud_cover_low                      float64\n",
              "cloud_cover_mid                      float64\n",
              "cloud_cover_high                     float64\n",
              "et0_fao_evapotranspiration           float64\n",
              "vapour_pressure_deficit              float64\n",
              "wind_speed_10m                       float64\n",
              "wind_speed_100m                      float64\n",
              "wind_direction_10m                   float64\n",
              "wind_direction_100m                  float64\n",
              "wind_gusts_10m                       float64\n",
              "sunshine_duration                    float64\n",
              "dtype: object"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "i047SY3AsTK0",
        "outputId": "b5c60076-adb8-45d6-bb5f-7d62729ae7a8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>temperature_2m</th>\n",
              "      <th>relative_humidity_2m</th>\n",
              "      <th>dew_point_2m</th>\n",
              "      <th>precipitation</th>\n",
              "      <th>rain</th>\n",
              "      <th>snowfall</th>\n",
              "      <th>snow_depth</th>\n",
              "      <th>weather_code</th>\n",
              "      <th>pressure_msl</th>\n",
              "      <th>...</th>\n",
              "      <th>cloud_cover_mid</th>\n",
              "      <th>cloud_cover_high</th>\n",
              "      <th>et0_fao_evapotranspiration</th>\n",
              "      <th>vapour_pressure_deficit</th>\n",
              "      <th>wind_speed_10m</th>\n",
              "      <th>wind_speed_100m</th>\n",
              "      <th>wind_direction_10m</th>\n",
              "      <th>wind_direction_100m</th>\n",
              "      <th>wind_gusts_10m</th>\n",
              "      <th>sunshine_duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>131494</th>\n",
              "      <td>2024-01-01 22:00:00</td>\n",
              "      <td>-13.721</td>\n",
              "      <td>80.381676</td>\n",
              "      <td>-16.371</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1016.9</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.041773</td>\n",
              "      <td>6.763786</td>\n",
              "      <td>12.429127</td>\n",
              "      <td>154.79890</td>\n",
              "      <td>190.00792</td>\n",
              "      <td>26.28</td>\n",
              "      <td>0.679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131495</th>\n",
              "      <td>2024-01-01 23:00:00</td>\n",
              "      <td>-13.421</td>\n",
              "      <td>78.443700</td>\n",
              "      <td>-16.371</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1015.7</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.047036</td>\n",
              "      <td>6.439876</td>\n",
              "      <td>12.605142</td>\n",
              "      <td>153.43501</td>\n",
              "      <td>181.63654</td>\n",
              "      <td>27.00</td>\n",
              "      <td>0.679</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      date  temperature_2m  relative_humidity_2m  \\\n",
              "131494 2024-01-01 22:00:00         -13.721             80.381676   \n",
              "131495 2024-01-01 23:00:00         -13.421             78.443700   \n",
              "\n",
              "        dew_point_2m  precipitation  rain  snowfall  snow_depth  weather_code  \\\n",
              "131494       -16.371            0.0   0.0       0.0        1.23           3.0   \n",
              "131495       -16.371            0.0   0.0       0.0        1.23           1.0   \n",
              "\n",
              "        pressure_msl  ...  cloud_cover_mid  cloud_cover_high  \\\n",
              "131494        1016.9  ...              2.0             100.0   \n",
              "131495        1015.7  ...              0.0              40.0   \n",
              "\n",
              "        et0_fao_evapotranspiration  vapour_pressure_deficit  wind_speed_10m  \\\n",
              "131494                         0.0                 0.041773        6.763786   \n",
              "131495                         0.0                 0.047036        6.439876   \n",
              "\n",
              "        wind_speed_100m  wind_direction_10m  wind_direction_100m  \\\n",
              "131494        12.429127           154.79890            190.00792   \n",
              "131495        12.605142           153.43501            181.63654   \n",
              "\n",
              "        wind_gusts_10m  sunshine_duration  \n",
              "131494           26.28              0.679  \n",
              "131495           27.00              0.679  \n",
              "\n",
              "[2 rows x 23 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tail(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhxU7l0ksTK0"
      },
      "source": [
        "## 1.1 Splitting and scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "hGW2HYCesTK0"
      },
      "outputs": [],
      "source": [
        "df = df.drop_duplicates()\n",
        "df = df.dropna()\n",
        "df['date'] = pd.to_datetime(df['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "8mqCsr5CsTK1",
        "outputId": "3c3cdf1c-d9f0-4d21-c841-3426bd7b3b85"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>temperature_2m</th>\n",
              "      <th>relative_humidity_2m</th>\n",
              "      <th>dew_point_2m</th>\n",
              "      <th>precipitation</th>\n",
              "      <th>rain</th>\n",
              "      <th>snowfall</th>\n",
              "      <th>snow_depth</th>\n",
              "      <th>weather_code</th>\n",
              "      <th>pressure_msl</th>\n",
              "      <th>...</th>\n",
              "      <th>cloud_cover_mid</th>\n",
              "      <th>cloud_cover_high</th>\n",
              "      <th>et0_fao_evapotranspiration</th>\n",
              "      <th>vapour_pressure_deficit</th>\n",
              "      <th>wind_speed_10m</th>\n",
              "      <th>wind_speed_100m</th>\n",
              "      <th>wind_direction_10m</th>\n",
              "      <th>wind_direction_100m</th>\n",
              "      <th>wind_gusts_10m</th>\n",
              "      <th>sunshine_duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-01-01 00:00:00</td>\n",
              "      <td>-10.842501</td>\n",
              "      <td>72.968170</td>\n",
              "      <td>-14.742500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.92</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1025.2</td>\n",
              "      <td>...</td>\n",
              "      <td>95.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.001225</td>\n",
              "      <td>0.072607</td>\n",
              "      <td>6.989935</td>\n",
              "      <td>11.275530</td>\n",
              "      <td>191.88864</td>\n",
              "      <td>196.69933</td>\n",
              "      <td>29.880000</td>\n",
              "      <td>-0.1425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-01-01 01:00:00</td>\n",
              "      <td>-10.642500</td>\n",
              "      <td>73.911520</td>\n",
              "      <td>-14.392500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.92</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1025.2</td>\n",
              "      <td>...</td>\n",
              "      <td>95.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071200</td>\n",
              "      <td>5.860375</td>\n",
              "      <td>8.557102</td>\n",
              "      <td>190.61960</td>\n",
              "      <td>202.24907</td>\n",
              "      <td>25.560000</td>\n",
              "      <td>-0.1425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-01-01 02:00:00</td>\n",
              "      <td>-10.492500</td>\n",
              "      <td>74.547844</td>\n",
              "      <td>-14.142500</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.92</td>\n",
              "      <td>71.0</td>\n",
              "      <td>1025.0</td>\n",
              "      <td>...</td>\n",
              "      <td>89.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070298</td>\n",
              "      <td>5.154416</td>\n",
              "      <td>6.696387</td>\n",
              "      <td>192.09474</td>\n",
              "      <td>216.25392</td>\n",
              "      <td>20.160000</td>\n",
              "      <td>-0.1925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-01-01 03:00:00</td>\n",
              "      <td>-10.442499</td>\n",
              "      <td>75.476270</td>\n",
              "      <td>-13.942499</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.92</td>\n",
              "      <td>71.0</td>\n",
              "      <td>1025.3</td>\n",
              "      <td>...</td>\n",
              "      <td>92.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.068005</td>\n",
              "      <td>3.758510</td>\n",
              "      <td>4.896529</td>\n",
              "      <td>196.69933</td>\n",
              "      <td>252.89719</td>\n",
              "      <td>15.119999</td>\n",
              "      <td>-0.1925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-01-01 04:00:00</td>\n",
              "      <td>-10.542500</td>\n",
              "      <td>78.596596</td>\n",
              "      <td>-13.542500</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.93</td>\n",
              "      <td>71.0</td>\n",
              "      <td>1025.5</td>\n",
              "      <td>...</td>\n",
              "      <td>92.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.058886</td>\n",
              "      <td>2.099143</td>\n",
              "      <td>5.860375</td>\n",
              "      <td>239.03630</td>\n",
              "      <td>317.48960</td>\n",
              "      <td>14.759999</td>\n",
              "      <td>-0.1925</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 date  temperature_2m  relative_humidity_2m  dew_point_2m  \\\n",
              "0 2009-01-01 00:00:00      -10.842501             72.968170    -14.742500   \n",
              "1 2009-01-01 01:00:00      -10.642500             73.911520    -14.392500   \n",
              "2 2009-01-01 02:00:00      -10.492500             74.547844    -14.142500   \n",
              "3 2009-01-01 03:00:00      -10.442499             75.476270    -13.942499   \n",
              "4 2009-01-01 04:00:00      -10.542500             78.596596    -13.542500   \n",
              "\n",
              "   precipitation  rain  snowfall  snow_depth  weather_code  pressure_msl  ...  \\\n",
              "0            0.0   0.0      0.00        0.92           3.0        1025.2  ...   \n",
              "1            0.0   0.0      0.00        0.92           3.0        1025.2  ...   \n",
              "2            0.1   0.0      0.07        0.92          71.0        1025.0  ...   \n",
              "3            0.1   0.0      0.07        0.92          71.0        1025.3  ...   \n",
              "4            0.2   0.0      0.14        0.93          71.0        1025.5  ...   \n",
              "\n",
              "   cloud_cover_mid  cloud_cover_high  et0_fao_evapotranspiration  \\\n",
              "0             95.0              24.0                    0.001225   \n",
              "1             95.0              46.0                    0.000000   \n",
              "2             89.0              51.0                    0.000000   \n",
              "3             92.0              75.0                    0.000000   \n",
              "4             92.0              81.0                    0.000000   \n",
              "\n",
              "   vapour_pressure_deficit  wind_speed_10m  wind_speed_100m  \\\n",
              "0                 0.072607        6.989935        11.275530   \n",
              "1                 0.071200        5.860375         8.557102   \n",
              "2                 0.070298        5.154416         6.696387   \n",
              "3                 0.068005        3.758510         4.896529   \n",
              "4                 0.058886        2.099143         5.860375   \n",
              "\n",
              "   wind_direction_10m  wind_direction_100m  wind_gusts_10m  sunshine_duration  \n",
              "0           191.88864            196.69933       29.880000            -0.1425  \n",
              "1           190.61960            202.24907       25.560000            -0.1425  \n",
              "2           192.09474            216.25392       20.160000            -0.1925  \n",
              "3           196.69933            252.89719       15.119999            -0.1925  \n",
              "4           239.03630            317.48960       14.759999            -0.1925  \n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "eKRRUTghsTK1"
      },
      "outputs": [],
      "source": [
        "def label_encode_columns(cat_data, cat_columns):\n",
        "    \"\"\"Apply LabelEncoder to specified categorical columns.\"\"\"\n",
        "    for col in cat_columns:\n",
        "        cat_data[col] = LabelEncoder().fit_transform(cat_data[col])\n",
        "    return cat_data\n",
        "\n",
        "def preprocess(data):\n",
        "    \"\"\"\n",
        "    Process the input data X by adding cylical feature, applying label encoding to categorical columns\n",
        "    and standard scaling to numerical columns.\n",
        "    Parameters:\n",
        "        X (pd.DataFrame): Input dataframe to process.\n",
        "    Returns:\n",
        "        pd.DataFrame: Processed dataframe.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check if the DataFrame index is a datetime-like index\n",
        "    if not isinstance(data.index, pd.DatetimeIndex):\n",
        "        raise ValueError(\"The DataFrame index must be a datetime-like index (e.g., pd.DatetimeIndex). \"\n",
        "                        \"Ensure your DataFrame has a datetime index using data.set_index().\")\n",
        "\n",
        "    #Add cyclical features\n",
        "    data['hour_sin'] = np.sin(2 * np.pi * data.index.hour / 24)\n",
        "    data['hour_cos'] = np.cos(2 * np.pi * data.index.hour / 24)\n",
        "\n",
        "    data['day_of_week_sin'] = np.sin(2 * np.pi * data.index.dayofweek / 7)\n",
        "    data['day_of_week_cos'] = np.cos(2 * np.pi * data.index.dayofweek / 7)\n",
        "\n",
        "    data['month_sin'] = np.sin(2 * np.pi * (data.index.month - 1) / 12)\n",
        "    data['month_cos'] = np.cos(2 * np.pi * (data.index.month - 1) / 12)\n",
        "\n",
        "    # Define categorical and numerical columns\n",
        "    cat_columns = ['weather_code']\n",
        "    num_columns = data.drop(columns=cat_columns).select_dtypes(include=['float64']).columns.tolist()\n",
        "\n",
        "    # Helper function to generate column names for label-encoded columns\n",
        "    def get_label_encoded_column_names(cat_columns):\n",
        "        return [f\"{col}_encoded\" for col in cat_columns]\n",
        "\n",
        "    # Define the ColumnTransformer\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            # Apply FunctionTransformer to label encode categorical columns\n",
        "            ('label_encoder', FunctionTransformer(lambda data: label_encode_columns(data, cat_columns), validate=False), cat_columns),\n",
        "\n",
        "            # Apply StandardScaler to numerical columns\n",
        "            ('standard_scaler', StandardScaler(), num_columns)\n",
        "        ],\n",
        "        remainder='passthrough'  # Keeps other columns as is\n",
        "    )\n",
        "\n",
        "    # Create the pipeline\n",
        "    preprocess_pipe = make_pipeline(preprocessor)\n",
        "\n",
        "    # Process and return the transformed data\n",
        "    processed_data = preprocess_pipe.fit_transform(data)\n",
        "\n",
        "    # Convert to DataFrame to maintain column names\n",
        "    processed_columns = get_label_encoded_column_names(cat_columns) + num_columns + list(data.columns.difference(cat_columns + num_columns))\n",
        "\n",
        "    print(\"✅ Processed data, with shape\", processed_data.shape)\n",
        "\n",
        "    # print(processed_columns)\n",
        "\n",
        "    return pd.DataFrame(processed_data, columns=processed_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "uCvcUe0tsTK1"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns = 'wind_speed_10m')\n",
        "X['date'] = pd.to_datetime(X['date'])\n",
        "X.set_index('date', inplace=True)\n",
        "y = df.wind_speed_10m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_A4OefNsTK1",
        "outputId": "bcf389e8-e7bc-4ad7-d65e-ee0e9898fb35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Processed data, with shape (131496, 27)\n"
          ]
        }
      ],
      "source": [
        "X_processed = preprocess(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "P0IAOXUVsTK1"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([y.reset_index(drop=True), X_processed], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "bSWa4vV2sTK1",
        "outputId": "403bd717-b526-4454-a887-30bf743b95f8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wind_speed_10m</th>\n",
              "      <th>weather_code_encoded</th>\n",
              "      <th>temperature_2m</th>\n",
              "      <th>relative_humidity_2m</th>\n",
              "      <th>dew_point_2m</th>\n",
              "      <th>precipitation</th>\n",
              "      <th>rain</th>\n",
              "      <th>snowfall</th>\n",
              "      <th>snow_depth</th>\n",
              "      <th>pressure_msl</th>\n",
              "      <th>...</th>\n",
              "      <th>wind_direction_10m</th>\n",
              "      <th>wind_direction_100m</th>\n",
              "      <th>wind_gusts_10m</th>\n",
              "      <th>sunshine_duration</th>\n",
              "      <th>hour_sin</th>\n",
              "      <th>hour_cos</th>\n",
              "      <th>day_of_week_sin</th>\n",
              "      <th>day_of_week_cos</th>\n",
              "      <th>month_sin</th>\n",
              "      <th>month_cos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.989935</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-1.565276</td>\n",
              "      <td>-0.359492</td>\n",
              "      <td>-1.676971</td>\n",
              "      <td>-0.389763</td>\n",
              "      <td>-0.272938</td>\n",
              "      <td>-0.289634</td>\n",
              "      <td>0.821605</td>\n",
              "      <td>0.915229</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.038465</td>\n",
              "      <td>0.000227</td>\n",
              "      <td>0.164295</td>\n",
              "      <td>-0.722739</td>\n",
              "      <td>2.619209e-17</td>\n",
              "      <td>1.414214</td>\n",
              "      <td>0.614121</td>\n",
              "      <td>-1.273928</td>\n",
              "      <td>0.004523</td>\n",
              "      <td>1.419691</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   wind_speed_10m  weather_code_encoded  temperature_2m  relative_humidity_2m  \\\n",
              "0        6.989935                   3.0       -1.565276             -0.359492   \n",
              "\n",
              "   dew_point_2m  precipitation      rain  snowfall  snow_depth  pressure_msl  \\\n",
              "0     -1.676971      -0.389763 -0.272938 -0.289634    0.821605      0.915229   \n",
              "\n",
              "   ...  wind_direction_10m  wind_direction_100m  wind_gusts_10m  \\\n",
              "0  ...           -0.038465             0.000227        0.164295   \n",
              "\n",
              "   sunshine_duration      hour_sin  hour_cos  day_of_week_sin  \\\n",
              "0          -0.722739  2.619209e-17  1.414214         0.614121   \n",
              "\n",
              "   day_of_week_cos  month_sin  month_cos  \n",
              "0        -1.273928   0.004523   1.419691  \n",
              "\n",
              "[1 rows x 28 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(os.path.join(relative_path, 'raw_data/preprocessed_historical_data_windspeed.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tbx8nVHsTK1"
      },
      "source": [
        "# 2. Folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "f9F0A7NRsTK1"
      },
      "outputs": [],
      "source": [
        "target2 = 'wind_speed_10m'\n",
        "\n",
        "FOLD_LENGTH = df.shape[0] # each fold will have the whole dataset --> only 1 fold in this model\n",
        "FOLD_STRIDE = 1 # sliding only on hour\n",
        "TRAIN_TEST_RATIO = 0.66\n",
        "split_index = int(df.shape[0] * TRAIN_TEST_RATIO)\n",
        "\n",
        "# Inputs\n",
        "N_FEATURES = df.shape[1] - 1\n",
        "INPUT_LENGTH = 48 # 48 hours input = forecast the upcooming 48 hours\n",
        "\n",
        "# Outputs\n",
        "TARGET = target2\n",
        "N_TARGETS = 1\n",
        "OUTPUT_LENGTH = N_TARGETS * 48 # - Predicting one target, the temperature - for two days with predictions every hour\n",
        "\n",
        "# Additional parameters\n",
        "HORIZON = 1 # - We are predicting next two days\n",
        "TARGET_COLUMN_IDX = df.columns.get_loc(target2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7imOJijYsTK2",
        "outputId": "f179460b-2af9-40db-fabe-25ae5c6723fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DS includes 131496 rows --> hours\n",
            "DS includes 782.7142857142857 --> weeks\n",
            "DS includes 195.67857142857142 --> months\n",
            "DS includes 16.306547619047617 --> years\n"
          ]
        }
      ],
      "source": [
        "rows = FOLD_LENGTH\n",
        "days = rows/24\n",
        "weeks = days/7\n",
        "months = weeks/4\n",
        "years = months/ 12\n",
        "print(f'DS includes {rows} rows --> hours')\n",
        "print(f'DS includes {weeks} --> weeks')\n",
        "print(f'DS includes {months} --> months')\n",
        "print(f'DS includes {years} --> years')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "v2QoXQansTK2"
      },
      "outputs": [],
      "source": [
        "def get_folds(\n",
        "    df: pd.DataFrame,\n",
        "    fold_length: int,\n",
        "    fold_stride: int) -> List[pd.DataFrame]:\n",
        "    '''\n",
        "    This function slides through the Time Series dataframe of shape (n_timesteps, n_features) to create folds\n",
        "    - of equal `fold_length`\n",
        "    - using `fold_stride` between each fold\n",
        "\n",
        "    Returns a list of folds, each as a DataFrame\n",
        "    '''\n",
        "\n",
        "    folds = []\n",
        "    for idx in range(0, len(df), fold_stride):\n",
        "        # Exits the loop as soon as the last fold index would exceed the last index\n",
        "        if (idx + fold_length) > len(df):\n",
        "            break\n",
        "        fold = df.iloc[idx:idx + fold_length, :]\n",
        "        folds.append(fold)\n",
        "    return folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Mk3w8BLsTK2",
        "outputId": "23b619f8-fdc3-4ab9-c9ff-c4451ddcc3f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The function generated 1 folds.\n",
            "Each fold has a shape equal to (131496, 28).\n"
          ]
        }
      ],
      "source": [
        "folds = get_folds(df, FOLD_LENGTH, FOLD_STRIDE)\n",
        "\n",
        "print(f'The function generated {len(folds)} folds.')\n",
        "print(f'Each fold has a shape equal to {folds[0].shape}.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "0P5e0WGOsTK2"
      },
      "outputs": [],
      "source": [
        "fold = folds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUZE5YrpsTK2",
        "outputId": "09be5c4a-7f6e-44f3-eaf3-fe5e72189eff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(131496, 28)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fold.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czHX7YklsTK2"
      },
      "source": [
        "# 3. Creating Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "246qSzaysTK2"
      },
      "outputs": [],
      "source": [
        "def train_test_split(fold: pd.DataFrame,\n",
        "                     train_test_ratio: float,\n",
        "                     input_length: int,\n",
        "                     horizon: int) -> Tuple[pd.DataFrame]:\n",
        "    '''\n",
        "    Returns a train dataframe and a test dataframe (fold_train, fold_test)\n",
        "    from which one can sample (X,y) sequences.\n",
        "    df_train should contain all the timesteps until round(train_test_ratio * len(fold))\n",
        "    '''\n",
        "\n",
        "    # TRAIN SET\n",
        "    # ======================\n",
        "    last_train_idx = round(train_test_ratio * len(fold))\n",
        "    fold_train = fold.iloc[0:last_train_idx, :]\n",
        "\n",
        "    # TEST SET\n",
        "    # ======================\n",
        "    first_test_idx = last_train_idx - input_length\n",
        "    fold_test = fold.iloc[first_test_idx:, :]\n",
        "\n",
        "    return (fold_train, fold_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "5TeVG_8esTK2"
      },
      "outputs": [],
      "source": [
        "(fold_train, fold_test) = train_test_split(fold,\n",
        "                                           TRAIN_TEST_RATIO,\n",
        "                                           INPUT_LENGTH,\n",
        "                                           HORIZON)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10r-ywpdsTK2",
        "outputId": "918f7969-bbc5-48ab-a2c1-b0ab2a1d4caf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((86787, 28), (44757, 28))"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fold_train.shape, fold_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY5umidnsTK2",
        "outputId": "aa5d5be7-f7ff-4045-baf0-24e1b0ff5489"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fold_train.index[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySHyLALwsTK2",
        "outputId": "286f9568-713b-41bf-cc0b-93d428d1ac36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##### INPUTS #####\n",
            "- INPUT_LENGTH = 48 timesteps = 2 days = 0 weeks\n",
            "- N_FEATURES = 27\n",
            "##### OUTPUTS #####\n",
            "- OUTPUT_LENGTH = 48 timesteps = 2 day(s)\n",
            "- N_TARGETS = 1\n",
            "##### PARAMETERS #####\n",
            "- HORIZON = 1 timesteps = 0 day(s)\n",
            "##### TRAIN SET #####\n",
            "- The training fold starts at index 0 and stops at index 86786.\n",
            "##### TEST SET #####\n",
            "- The test fold starts at index 86739 and stops at index 131495.\n"
          ]
        }
      ],
      "source": [
        "# Inputs\n",
        "print(\"##### INPUTS #####\")\n",
        "print(f'- INPUT_LENGTH = {INPUT_LENGTH} timesteps = {int(INPUT_LENGTH/24)} days = {int(INPUT_LENGTH/24/7)} weeks')\n",
        "print(f'- N_FEATURES = {N_FEATURES}')\n",
        "# Outputs\n",
        "print(\"##### OUTPUTS #####\")\n",
        "print(f'- OUTPUT_LENGTH = {OUTPUT_LENGTH} timesteps = {int(OUTPUT_LENGTH/24)} day(s)')\n",
        "print(f'- N_TARGETS = {N_TARGETS}')\n",
        "# Parameters\n",
        "print(\"##### PARAMETERS #####\")\n",
        "print(f'- HORIZON = {HORIZON} timesteps = {int(HORIZON/24)} day(s)')\n",
        "# Train\n",
        "print(\"##### TRAIN SET #####\")\n",
        "print(f\"- The training fold starts at index {fold_train.index[0]} and stops at index {fold_train.index[-1]}.\")\n",
        "# Test\n",
        "print(\"##### TEST SET #####\")\n",
        "print(f\"- The test fold starts at index {fold_test.index[0]} and stops at index {fold_test.index[-1]}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cLlhzuhsTK3",
        "outputId": "82d28272-88e7-4cfa-b823-396b0a1e75dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STRIDE = 1 timesteps = 0 day(s)\n"
          ]
        }
      ],
      "source": [
        "# New: Scanning  through a fold\n",
        "STRIDE = 1 # sliding every day, for instance\n",
        "print(f'STRIDE = {STRIDE} timesteps = {int(STRIDE/24)} day(s)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "NRHn5WUpsTK3"
      },
      "outputs": [],
      "source": [
        "def get_Xi_yi(first_index: int,\n",
        "              fold: pd.DataFrame,\n",
        "              horizon: int,\n",
        "              input_length: int,\n",
        "              output_length: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    '''\n",
        "    - extracts one sequence from a fold\n",
        "    - returns a pair (Xi, yi) with:\n",
        "        * len(Xi) = `input_length` and Xi starting at first_index\n",
        "        * len(yi) = `output_length`\n",
        "        * last_Xi and first_yi separated by the gap = horizon -1\n",
        "    '''\n",
        "\n",
        "    Xi_start = first_index\n",
        "    Xi_last = Xi_start + input_length\n",
        "    yi_start = Xi_last + horizon - 1\n",
        "    yi_last = yi_start + output_length\n",
        "\n",
        "    Xi = fold[Xi_start:Xi_last]\n",
        "    yi = fold[yi_start:yi_last][TARGET]\n",
        "\n",
        "    return (Xi, yi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "lkWhtXCAsTK3"
      },
      "outputs": [],
      "source": [
        "def get_X_y(fold: pd.DataFrame,\n",
        "            horizon: int,\n",
        "            input_length: int,\n",
        "            output_length: int,\n",
        "            stride: int,\n",
        "            shuffle=False) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    - Uses `data`, a 2D-array with axis=0 for timesteps, and axis=1 for (targets+covariates columns)\n",
        "    - Returns a Tuple (X,y) of two ndarrays :\n",
        "        * X.shape = (n_samples, input_length, n_covariates)\n",
        "        * y.shape =\n",
        "            (n_samples, output_length, n_targets) if all 3-dimensions are of size > 1\n",
        "            (n_samples, output_length) if n_targets == 1\n",
        "            (n_samples, n_targets) if output_length == 1\n",
        "            (n_samples, ) if both n_targets and lenghts == 1\n",
        "    - You can shuffle the pairs (Xi,yi) of your fold\n",
        "    \"\"\"\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(0, len(fold), stride):\n",
        "        ## Extracting a sequence starting at index_i\n",
        "        Xi, yi = get_Xi_yi(first_index=i,\n",
        "                           fold=fold,\n",
        "                           horizon=horizon,\n",
        "                           input_length=input_length,\n",
        "                           output_length=output_length)\n",
        "        ## Exits loop as soon as we reach the end of the dataset\n",
        "        if len(yi) < output_length:\n",
        "            break\n",
        "        X.append(Xi)\n",
        "        y.append(yi)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    y = np.squeeze(y)\n",
        "\n",
        "    if shuffle:\n",
        "        idx = np.arange(len(X))\n",
        "        np.random.shuffle(idx)\n",
        "        X = X[idx]\n",
        "        y = y[idx]\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhRQwuwEsTK3",
        "outputId": "25386e5c-0562-4a07-a3a5-4e2310c00f04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes for the training set:\n",
            "X_train.shape = (86692, 48, 28), y_train.shape = (86692, 48)\n",
            "Shapes for the test set:\n",
            "X_test.shape = (44662, 48, 28), y_test.shape = (44662, 48)\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = get_X_y(fold=fold_train,\n",
        "                           horizon=HORIZON,\n",
        "                           input_length=INPUT_LENGTH,\n",
        "                           output_length=OUTPUT_LENGTH,\n",
        "                           stride=STRIDE)\n",
        "X_test, y_test = get_X_y(fold=fold_test,\n",
        "                         horizon=HORIZON,\n",
        "                         input_length=INPUT_LENGTH,\n",
        "                         output_length=OUTPUT_LENGTH,\n",
        "                         stride=STRIDE)\n",
        "\n",
        "print(\"Shapes for the training set:\")\n",
        "print(f\"X_train.shape = {X_train.shape}, y_train.shape = {y_train.shape}\")\n",
        "\n",
        "print(\"Shapes for the test set:\")\n",
        "print(f\"X_test.shape = {X_test.shape}, y_test.shape = {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIrzilZzsTK3"
      },
      "source": [
        "# 4. Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHSKaQqTsTK3"
      },
      "source": [
        "## 4.1 Main Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "p7XzewQfsTK3",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers, metrics\n",
        "from tensorflow.keras.layers import Normalization, BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def init_model(X_train):\n",
        "    reg_l2 = regularizers.L2(0.1)\n",
        "\n",
        "    #========================================================================================\n",
        "\n",
        "    # 1 - RNN architecture\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "    # Recurrent Layer\n",
        "    model.add(layers.LSTM(units=32, activation='tanh',return_sequences=True,\n",
        "                        #   recurrent_dropout=0.3,dropout=0.3\n",
        "                        )\n",
        "                          )\n",
        "\n",
        "    # Hidden Dense Layer that we are regularizing\n",
        "    model.add(layers.Dense(16, activation=\"relu\",\n",
        "                        #    kernel_regularizer = reg_l2\n",
        "                        )\n",
        "                           )\n",
        "    # model.add(layers.Dropout(rate=0.3))\n",
        "\n",
        "    # Predictive Dense Layer\n",
        "    model.add(layers.Dense(1, activation='linear'))\n",
        "\n",
        "    #========================================================================================\n",
        "\n",
        "    # 2 - Compiler\n",
        "    optimizer = Adam(learning_rate=0.0001)\n",
        "    model.compile(loss='mse', optimizer=optimizer, metrics=[\"mae\"])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "zXBifPGmsTK7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "def fit_model(model: tf.keras.Model, verbose=1) -> Tuple[tf.keras.Model, dict]:\n",
        "\n",
        "    es = EarlyStopping(\n",
        "        monitor=\"val_mae\",\n",
        "        patience=10,\n",
        "        mode=\"min\",\n",
        "        restore_best_weights=True)\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_mae',\n",
        "        factor=0.1,\n",
        "        patience=5,\n",
        "        min_lr=1e-6)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        validation_split=0.3,\n",
        "        shuffle=False,\n",
        "        batch_size=64,\n",
        "        epochs=100,\n",
        "        callbacks=[es, reduce_lr],\n",
        "        verbose=verbose)\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "4R84irUzsTK7",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "\n",
        "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
        "    # --- LOSS: MSE ---\n",
        "    ax[0].plot(history.history['loss'])\n",
        "    ax[0].plot(history.history['val_loss'])\n",
        "    ax[0].set_title('MSE')\n",
        "    ax[0].set_ylabel('Loss')\n",
        "    ax[0].set_xlabel('Epoch')\n",
        "    ax[0].legend(['Train', 'Validation'], loc='best')\n",
        "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
        "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
        "\n",
        "    # --- METRICS:MAE ---\n",
        "\n",
        "    ax[1].plot(history.history['mae'])\n",
        "    ax[1].plot(history.history['val_mae'])\n",
        "    ax[1].set_title('MAE')\n",
        "    ax[1].set_ylabel('MAE')\n",
        "    ax[1].set_xlabel('Epoch')\n",
        "    ax[1].legend(['Train', 'Validation'], loc='best')\n",
        "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
        "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
        "\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "mstvXm0zsTK7",
        "outputId": "e2d414a3-1cec-4da3-c2bb-815cbd2c565a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-18 23:17:02.924802: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m7,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,353</span> (32.63 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,353\u001b[0m (32.63 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,353</span> (32.63 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,353\u001b[0m (32.63 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = init_model(X_train)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArjGkf-FsTK7",
        "outputId": "dbe0a9bd-c5c1-4e27-d01a-3cbf946069c8",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m949/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 50ms/step - loss: 20.8960 - mae: 3.8193 - val_loss: 7.0585 - val_mae: 2.0486 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m926/949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 6.3805 - mae: 2.0396"
          ]
        }
      ],
      "source": [
        "# 2 - Training\n",
        "# ====================================\n",
        "model, history = fit_model(model, verbose=1)\n",
        "\n",
        "plot_history(history);\n",
        "\n",
        "# 3 - Evaluation\n",
        "# ====================================\n",
        "res = model.evaluate(X_test, y_test)\n",
        "print(\"-\"*50)\n",
        "print(f\"The LSTM MAE on the test set is equal to {round(res[1],2)} km/h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWftsO2zvzqh"
      },
      "outputs": [],
      "source": [
        "model.save(os.path.join(relative_path, 'models/windspeed/wind_model.keras')) # save in keras compressed format\n",
        "model.save(os.path.join(relative_path, 'models/windspeed/wind_model.h5') # save in h5 compressed format\n",
        "model.save(os.path.join(relative_path, 'models/windspeed/wind_model', save_format='tf') # save in tf format, it should create a folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMuEYly2sTK7"
      },
      "source": [
        "## 4.2 Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t94Wfjk5sTK8"
      },
      "outputs": [],
      "source": [
        "def last_seen_value_baseline(X_test, y_test, target_column_idx=0):\n",
        "    \"\"\"\n",
        "    Baseline model that predicts the last observed value of the target variable (snowfall).\n",
        "\n",
        "    Parameters:\n",
        "    X: Input features (shape: [num_samples, time_steps, num_features])\n",
        "    y: Ground truth values (shape: [num_samples, time_steps, num_targets])\n",
        "    target_column_idx: Index of the target variable in the input features\n",
        "\n",
        "    Returns:\n",
        "    baseline_mae: Mean Absolute Error (MAE) of the baseline model\n",
        "    \"\"\"\n",
        "    # Get the last observed value of the target (temperature) for each sample\n",
        "    last_seen_values = X_test[:, -1, target_column_idx].reshape(-1, 1)\n",
        "\n",
        "    # Repeat this value for all the output steps\n",
        "    output_length = y_test.shape[1]  # Number of time steps in the target sequence\n",
        "    repeated = np.repeat(last_seen_values, axis=1, repeats=output_length)\n",
        "\n",
        "    # Calculate the MAE: Mean of absolute errors\n",
        "    mae = np.mean(np.abs(y_test - repeated))\n",
        "\n",
        "    return mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaAPBy_GsTK8"
      },
      "outputs": [],
      "source": [
        "# 1 - Evaluation of the Baseline Model\n",
        "# ====================================\n",
        "mae_baseline = last_seen_value_baseline(X_test, y_test, target_column_idx=0)\n",
        "print(f\"- The Baseline MAE on the test set is equal to {round(mae_baseline,2)} km/h\")\n",
        "\n",
        "# 4 - Comparison with the LSTM model\n",
        "# ====================================\n",
        "print(f\"- The LSTM MAE on the test set is equal to {round(res[1],2)} cm\")\n",
        "print(f\"👉 Improvement/decrease of the LSTM model over the baseline (on this fold for the test set): {round((1 - (res[1]/mae_baseline))*100,2)} % 👈\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-fPttSFsTK8"
      },
      "source": [
        "## 4.3 Optimizing on Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qbybh-fovrA5"
      },
      "outputs": [],
      "source": [
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awZuxNMLsTK8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras_tuner import HyperModel\n",
        "from keras_tuner import RandomSearch\n",
        "\n",
        "class LSTMModel(HyperModel):\n",
        "    def build(self, hp):\n",
        "        reg_l2 = regularizers.L2(hp.Float('l2_reg', min_value=0.001, max_value=0.1, step=0.001))\n",
        "\n",
        "        #========================================================================================\n",
        "\n",
        "        model = models.Sequential()\n",
        "\n",
        "        # Input Layer\n",
        "        model.add(layers.Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "        # Recurrent Layer with tunable units and dropout\n",
        "        model.add(layers.LSTM(\n",
        "            units=hp.Int('units', min_value=16, max_value=128, step=16),\n",
        "            activation='tanh',\n",
        "            return_sequences=True,\n",
        "            recurrent_dropout=hp.Float('recurrent_dropout', min_value=0.2, max_value=0.5, step=0.05),\n",
        "            dropout=hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.05)\n",
        "        ))\n",
        "        model.add(layers.LSTM(\n",
        "            units=hp.Int('units', min_value=16, max_value=128, step=16),\n",
        "            activation='tanh',\n",
        "            return_sequences=True,\n",
        "            recurrent_dropout=hp.Float('recurrent_dropout', min_value=0.2, max_value=0.5, step=0.05),\n",
        "            dropout=hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.05)\n",
        "        ))\n",
        "\n",
        "        # Hidden Dense Layer with tunable regularization\n",
        "        model.add(layers.Dense(\n",
        "            units=hp.Int('dense_units', min_value=32, max_value=128, step=32),\n",
        "            activation=\"relu\",\n",
        "            kernel_regularizer=reg_l2\n",
        "        ))\n",
        "        model.add(layers.Dropout(rate=hp.Float('dense_dropout', min_value=0.2, max_value=0.5, step=0.05)))\n",
        "\n",
        "        # Output Layer\n",
        "        model.add(layers.Dense(1, activation='linear'))\n",
        "\n",
        "        #========================================================================================\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(\n",
        "            loss='mse',\n",
        "            optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='log')),\n",
        "            metrics=[\"mae\"]\n",
        "        )\n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_4GKZ00sTK8"
      },
      "outputs": [],
      "source": [
        "tuner = RandomSearch(\n",
        "    LSTMModel(),  # The HyperModel class\n",
        "    objective='val_mae',  # We want to minimize validation MAE\n",
        "    max_trials=10,  # Number of different hyperparameter combinations to try\n",
        "    executions_per_trial=1,  # Number of models to train per trial\n",
        "    directory='models',  # Directory to store logs and models\n",
        "    project_name='windspeed_hyperparameters')\n",
        "\n",
        "tuner.search(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    validation_split=0.3,  # Use a validation split\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_mae', patience=2)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhsb38I-sTK8"
      },
      "outputs": [],
      "source": [
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Best Hyperparameters: {best_hps.values}\")\n",
        "\n",
        "# Build the best model with those hyperparameters\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Train the best model\n",
        "history = best_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_mae', patience=5)]\n",
        ")\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "test_results = best_model.evaluate(X_test, y_test)\n",
        "print(f\"Test MAE: {test_results[1]} km/h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-6CUDQfsTK8"
      },
      "outputs": [],
      "source": [
        "plot_history(history);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiEh6q04sTK8"
      },
      "source": [
        "# 4.4. Save/ Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxvXShpmsTK8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, save_model, load_model\n",
        "from tensorflow.keras import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9zKjgKAsTK9"
      },
      "outputs": [],
      "source": [
        "relative_path = os.path.dirname(current_dir)\n",
        "models_folder = os.path.join(relative_path, \"powder_alert2.0/models\")\n",
        "\n",
        "save_as_keras = os.path.join(models_folder, 'snowfall_FINAL.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nq4XnhPsTK9"
      },
      "outputs": [],
      "source": [
        "best_model.save(os.path.join(relative_path, 'models/windspeed/wind_model.keras')) # save in keras compressed format\n",
        "best_model.save(os.path.join(relative_path, 'models/windspeed/wind_model.h5') # save in h5 compressed format\n",
        "best_model.save(os.path.join(relative_path, 'models/windspeed/wind_model', save_format='tf') # save in tf format, it should cr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t81R4UEGsTK9"
      },
      "outputs": [],
      "source": [
        "loaded_model_keras = tf.keras.models.load_model(save_as_keras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2D70IZlsTK9"
      },
      "source": [
        "# 5. Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AWuNvedsTK9"
      },
      "outputs": [],
      "source": [
        "last_input = X_test[-1:]\n",
        "last_input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lZr5CyhsTK9"
      },
      "outputs": [],
      "source": [
        "best_model = loaded_model_keras # needs to be changed to load the best/ current model --> best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWig_23jsTK9"
      },
      "outputs": [],
      "source": [
        "predictions = best_model.predict(last_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xc29vGLsTK9"
      },
      "outputs": [],
      "source": [
        "predicted_temperatures = predictions[0]\n",
        "print(f'The snowfall for the upcoming 24 h ranges from {predicted_temperatures.min()} to {predicted_temperatures.max()} km/h.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDYpjrn5sTK9"
      },
      "outputs": [],
      "source": [
        "predicted_df = pd.DataFrame(predicted_temperatures, columns=[\"Predicted windspeed\"])\n",
        "predicted_df[\"Hour\"] = pd.date_range(start=pd.to_datetime('now'), periods=24, freq='h')\n",
        "\n",
        "# Plot the predicted temperatures\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(predicted_df[\"Hour\"], predicted_df[\"Predicted windspeed\"], marker='o')\n",
        "plt.title(\"Predicted windspeed for the Next 24 Hours\")\n",
        "plt.xlabel(\"Hour\")\n",
        "plt.ylabel(\"cm\")\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yrLkSrBsTK9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "conda-base-py",
      "name": "workbench-notebooks.m126",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
    },
    "kernelspec": {
      "display_name": "powder_alert2.0",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
